{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Regression - Inference Algorithms\n",
    "\n",
    "In the previous \"bayesian regression\" example, we looked at how to perform inference on a simple Bayesian linear regression model using SVI. In this tutorial, we’ll explore more expressive guides as well as exact inference techniques. We’ll use the same dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "assert pyro.__version__.startswith('1.8.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "smoke_test = ('CI in os.environ')\n",
    "pyro.set_rng_seed(1)\n",
    "DATA_URL = \"https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\"\n",
    "rugged_data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression\n",
    "Our goal is once again to predict log GDP per capita of a nation as a function of two features from the dataset - whether the nation is in Africa, and its Terrain Ruggedness Index, but we will explore more expressive guides.\n",
    "\n",
    "## Model + Guide\n",
    "We will write out the model again, similar to that in \"bayesian regression\", but explicitly without the use of PyroModule. We will write out each term in the regression, using the same priors. bA and bR are regression coefficients corresponding to is_cont_africa and ruggedness, a is the intercept, and bAR is the correlating factor between the two features.\n",
    "\n",
    "Writing down a guide will proceed in close analogy to the construction of our model, with the key difference that the guide parameters need to be trainable. To do this we register the guide parameters in the ParamStore using pyro.param(). Note the positive constraints on scale parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(is_cont_africa, ruggedness, log_gdp):\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 10.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    with pyro.plate(\"data\", len(ruggedness)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=log_gdp)\n",
    "\n",
    "def guide(is_cont_africa, ruggedness, log_gdp):\n",
    "    a_loc = pyro.param('a_loc', torch.tensor(0.))\n",
    "    a_scale = pyro.param('a_scale', torch.tensor(1.),\n",
    "                         constraint=constraints.positive)\n",
    "    sigma_loc = pyro.param('sigma_loc', torch.tensor(1.),\n",
    "                           constraint=constraints.positive)\n",
    "    weights_loc = pyro.param('weights_loc', torch.randn(3))\n",
    "    weights_scale = pyro.param('weights_scale', torch.ones(3),\n",
    "                               constraint=constraints.positive)\n",
    "    a = pyro.sample(\"a\", dist.Normal(a_loc, a_scale))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(weights_loc[0], weights_scale[0]))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(weights_loc[1], weights_scale[1]))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(weights_loc[2], weights_scale[2]))\n",
    "    sigma = pyro.sample(\"bAR\", dist.Normal(sigma_loc, torch.tensor(0.05)))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to print latent sites' quantile information\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats\n",
    "\n",
    "# prepare training data\n",
    "df = rugged_data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "train = torch.tensor(df.values, dtype=torch.float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Variational Inference (SVI)\n",
    "As before, we will use SVI to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyroVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
