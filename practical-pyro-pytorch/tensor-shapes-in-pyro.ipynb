{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "* Distribution shapes\n",
    "\n",
    "* * Examples\n",
    "\n",
    "* * Reshaping distributions\n",
    "\n",
    "* * It is always safe to assume dependence\n",
    "\n",
    "* Declaring independence with plate\n",
    "\n",
    "* Subsampling inside plate\n",
    "\n",
    "* Broadcasting to allow Parallel Enumeration\n",
    "\n",
    "* * Writing parallelizable code\n",
    "\n",
    "* * Automatic broadcasting inside pyro.plate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/Library/Mobile Documents/com~apple~CloudDocs/Git_Projects/Deep-probabilistic-modeling/PyroVenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "from torch.distributions import constraints\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.8.4')\n",
    "\n",
    "# we'll use this helper to check our models are correct\n",
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions shapes: batch_shape and event_shape\n",
    "\n",
    "PyTorch Tensors have a single .shape attribute, but Distributions have two shape attributions with special meaning: .batch_shape and .event_shape. These two combine to define the total shape of a sample.\n",
    "\n",
    "``` python\n",
    "x = d.sample()\n",
    "assert x.shape == d.batch_shape + d.event_shape\n",
    "\n",
    "```\n",
    "\n",
    "Indices over .batch_shape denote conditionally independent random variables, whereas indices over .event_shape denote dependent random variables (ie one draw from a distribution). Because the dependent random variables define probability together, the .log_prob() method only produces a single number for each event of shape .event_shape. Thus the total shape of .log_prob() is .batch_shape:\n",
    "\n",
    "```python\n",
    "assert d.log_prob(x).shape == d.batch_shape\n",
    "```\n",
    "\n",
    "Note that the Distribution.sample() method also takes a sample_shape parameter that indexes over independent identically distributed (iid) random varables, so that:\n",
    "\n",
    "```python\n",
    "x2 = d.sample(sample_shape)\n",
    "assert x2.shape == sample_shape + batch_shape + event_shape\n",
    "\n",
    "```\n",
    "\n",
    "in summary:\n",
    "\n",
    "```\n",
    "      |      iid     | independent | dependent\n",
    "------+--------------+-------------+------------\n",
    "shape = sample_shape + batch_shape + event_shape\n",
    "\n",
    "```\n",
    "\n",
    "For example univariate distributions have empty event shape (because each number is an independent event). Distributions over vectors like MultivariateNormal have len(event_shape) == 1. Distributions over matrices like InverseWishart have len(event_shape) == 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "The simplest distribution shape is a single univariate distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5)\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == ()\n",
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Distributions can be batched by passing in batched parameters.\n",
    "'''\n",
    "\n",
    "d = Bernoulli(0.5 * torch.ones(3, 4))\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Another way to batch distributions is via the .expand() method. This only works if parameters are identical along the leftmost dimensions.\n",
    "'''\n",
    "\n",
    "d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3, 4])\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate distributions have nonempty .event_shape. For these distributions, the shapes of .sample() and .log_prob(x) differ:\n",
    "'''\n",
    "\n",
    "d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3, )\n",
    "x = d.sample()\n",
    "assert x.shape == (3, )             # == batch_shape + even_shape \n",
    "assert d.log_prob(x).shape == ()    # == batch shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping distributions\n",
    "\n",
    "In Pyro you can treat a univariate distribution as multivariate by calling the .to_event(n) property where n is the number of batch dimensions (from the right) to declare as dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhile you work with Pyro programs, keep in mind that samples have\\nshape batch_shape + event_shape, whereas .log_prob(x) values have\\nshape batch_shape. You’ll need to ensure that batch_shape is carefully\\ncontrolled by either trimming it down with .to_event(n) or by declaring\\ndimensions as independent via pyro.plate.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3, 4)).to_event(1)\n",
    "assert d.batch_shape == (3, )\n",
    "assert d.event_shape == (4, )\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, )\n",
    "\n",
    "'''\n",
    "While you work with Pyro programs, keep in mind that samples have\n",
    "shape batch_shape + event_shape, whereas .log_prob(x) values have\n",
    "shape batch_shape. You’ll need to ensure that batch_shape is carefully\n",
    "controlled by either trimming it down with .to_event(n) or by declaring\n",
    "dimensions as independent via pyro.plate.\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is always safe to assume dependence\n",
    "\n",
    "Often in Pyro we’ll declare some dimensions as dependent even though they are in fact independent, e.g.\n",
    "\n",
    "``` python\n",
    "x = pyro.sample(\"x\", Normal(0, 1).expand([10]).to_event(1))\n",
    "assert x.shape == (10,)\n",
    "```\n",
    "\n",
    "This is useful for two reasons: First it allows us to easily swap in a MultivariateNormal distribution later. Second it simplifies the code a bit since we don’t need a plate (see below) as in\n",
    "\n",
    "``` python\n",
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", Normal(0, 1))  # .expand([10]) is automatic\n",
    "    assert x.shape == (10,)\n",
    "```\n",
    "\n",
    "The difference between these two versions is that the second version with plate informs Pyro that it can make use of conditional independence information when estimating gradients, whereas in the first version Pyro must assume they are dependent (even though the normals are in fact conditionally independent). This is analogous to d-separation in graphical models: it is always safe to add edges and assume variables may be dependent (i.e. to widen the model class), but it is unsafe to assume independence when variables are actually dependent (i.e. narrowing the model class so the true model lies outside of the class, as in mean field). In practice Pyro’s SVI inference algorithm uses reparameterized gradient estimators for Normal distributions so both gradient estimators have the same performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring independent dims with plate\n",
    "Pyro models can use the context manager pyro.plate to declare that certain batch dimensions are independent. Inference algorithms can then take advantage of this independence to e.g. construct lower variance gradient estimators or to enumerate in linear space rather than exponential space. An example of an independent dimension is the index over data in a minibatch: each datum should be independent of all others.\n",
    "\n",
    "The simplest way to declare a dimension as independent is to declare the rightmost batch dimension as independent via a simple\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"my_plate\"):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "We recommend always providing an optional size argument to aid in debugging shapes\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"my_plate\", len(my_data)):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "Starting with Pyro 0.2 you can additionally nest plates, e.g. if you have per-pixel independence:\n",
    "\n",
    "```python\n",
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent\n",
    "\n",
    "```\n",
    "\n",
    "Note that we always count from the right by using negative indices like -2, -1.\n",
    "\n",
    "Finally if you want to mix and match plates for e.g. noise that depends only on x, some noise that depends only on y, and some noise that depends on both, you can declare multiple plates and use them as reusable context managers. In this case Pyro cannot automatically allocate a dimension, so you need to provide a dim argument (again counting from the right):\n",
    "\n",
    "```python\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    # within this context, batch dimension -2 is independent\n",
    "with y_axis:\n",
    "    # within this context, batch dimension -3 is independent\n",
    "with x_axis, y_axis:\n",
    "    # within this context, batch dimensions -3 and -2 are independent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "let's take a closer look at batch sizes within \"plate\" s.\n",
    "'''\n",
    "\n",
    "def model1():\n",
    "    a = pyro.sample(\"a\", Normal(0, 1))\n",
    "    b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1))\n",
    "    with pyro.plate(\"c_plate\", 2):\n",
    "        c = pyro.sample(\"c\", Normal(torch.zeros(2), 1))\n",
    "    with pyro.plate(\"d_plate\", 3):\n",
    "        d = pyro.sample(\"d\", Normal(torch.zeros(3, 4, 5), 1).to_event(2))\n",
    "    assert a.shape == ()         # batch_shape == ()    event_shape == ()\n",
    "    assert b.shape == (2, )      # batch_shape == ()    event_shape == (2, )\n",
    "    assert c.shape == (2, )      # batch_shape == (2, ) event_shape == ()\n",
    "    assert d.shape == (3, 4, 5)  # batch_shape == (3, ) event_shape == (4, 5)\n",
    "\n",
    "    x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "    y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "    with x_axis:\n",
    "        x = pyro.sample(\"x\", Normal(0, 1))\n",
    "    with y_axis:\n",
    "        y = pyro.sample(\"y\", Normal(0, 1))\n",
    "    with x_axis, y_axis:\n",
    "        xy = pyro.sample(\"xy\", Normal(0, 1))\n",
    "        z = pyro.sample(\"z\", Normal(0, 1).expand([5]).to_event(1))\n",
    "    assert x.shape == (3, 1)       # batch_shape == (3, 1)     event_shape == ()\n",
    "    assert y.shape == (2, 1, 1)    # batch_shaoe == (2, 1, 1)   event_shape == ()\n",
    "    assert xy.shape == (2, 3, 1)   # batch__shape == (2, 3, 1)   event_shape == ()\n",
    "    assert z.shape ==(2, 3, 1, 5)  # batch_shaoe == (2, 3, 1)    event_shape == (5, )\n",
    "\n",
    "test_model(model1, model1, Trace_ELBO())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to visualize the .shapes of each sample site by aligning them at the boundary between batch_shape and event_shape: dimensions to the right will be summed out in .log_prob() and dimensions to the left will remain.\n",
    "\n",
    "```python\n",
    "batch dims | event dims\n",
    "-----------+-----------\n",
    "           |        a = sample(\"a\", Normal(0, 1))\n",
    "           |2       b = sample(\"b\", Normal(zeros(2), 1)\n",
    "           |                        .to_event(1))\n",
    "           |        with plate(\"c\", 2):\n",
    "          2|            c = sample(\"c\", Normal(zeros(2), 1))\n",
    "           |        with plate(\"d\", 3):\n",
    "          3|4 5         d = sample(\"d\", Normal(zeros(3,4,5), 1)\n",
    "           |                       .to_event(2))\n",
    "           |\n",
    "           |        x_axis = plate(\"x\", 3, dim=-2)\n",
    "           |        y_axis = plate(\"y\", 2, dim=-3)\n",
    "           |        with x_axis:\n",
    "        3 1|            x = sample(\"x\", Normal(0, 1))\n",
    "           |        with y_axis:\n",
    "      2 1 1|            y = sample(\"y\", Normal(0, 1))\n",
    "           |        with x_axis, y_axis:\n",
    "      2 3 1|            xy = sample(\"xy\", Normal(0, 1))\n",
    "      2 3 1|5           z = sample(\"z\", Normal(0, 1).expand([5])\n",
    "           |                       .to_event(1))\n",
    "```\n",
    "\n",
    "To examine the shapes of sample sites in a program automatically, you can trace the program and use the Trace.format_shapes() method, which prints three shapes for each sample site: the distribution shape (both site[\"fn\"].batch_shape and site[\"fn\"].event_shape), the value shape (site[\"value\"].shape), and if log probability has been computed also the log_prob shape (site[\"log_prob\"].shape):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:            \n",
      " Param Sites:            \n",
      "Sample Sites:            \n",
      "       a dist       |    \n",
      "        value       |    \n",
      "     log_prob       |    \n",
      "       b dist       | 2  \n",
      "        value       | 2  \n",
      "     log_prob       |    \n",
      " c_plate dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       c dist     2 |    \n",
      "        value     2 |    \n",
      "     log_prob     2 |    \n",
      " d_plate dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "       d dist     3 | 4 5\n",
      "        value     3 | 4 5\n",
      "     log_prob     3 |    \n",
      "  x_axis dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "  y_axis dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       x dist   3 1 |    \n",
      "        value   3 1 |    \n",
      "     log_prob   3 1 |    \n",
      "       y dist 2 1 1 |    \n",
      "        value 2 1 1 |    \n",
      "     log_prob 2 1 1 |    \n",
      "      xy dist 2 3 1 |    \n",
      "        value 2 3 1 |    \n",
      "     log_prob 2 3 1 |    \n",
      "       z dist 2 3 1 | 5  \n",
      "        value 2 3 1 | 5  \n",
      "     log_prob 2 3 1 |    \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(model1).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyroVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
