{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the PyTorch JIT Compiler with Pyro\n",
    "This tutorial shows how to use the PyTorch jit compiler in Pyro models.\n",
    "\n",
    "## Summary:\n",
    "* You can use compiled functions in Pyro models.\n",
    "\n",
    "* You cannot use pyro primitives inside compiled functions.\n",
    "\n",
    "* If your model has static structure, you can use a Jit* version of an ELBO algorithm, e.g.\n",
    "\n",
    "```\n",
    "- Trace_ELBO()\n",
    "+ JitTrace_ELBO()\n",
    "\n",
    "```\n",
    "* The HMC and NUTS classes accept jit_compile=True kwarg.\n",
    "\n",
    "* Models should input all tensors as *args and all non-tensors as **kwargs.\n",
    "\n",
    "* Each different value of **kwargs triggers a separate compilation.\n",
    "\n",
    "* Use **kwargs to specify all variation in structure (e.g. time series length).\n",
    "\n",
    "* To ignore jit warnings in safe code blocks, use with pyro.util.ignore_jit_warnings():.\n",
    "\n",
    "* To ignore all jit warnings in HMC or NUTS, pass ignore_jit_warnings=True.\n",
    "\n",
    "## Table of contents\n",
    "* Introduction\n",
    "\n",
    "* A simple model\n",
    "\n",
    "* Varying structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from pyro import poutine\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, JitTrace_ELBO, TraceEnum_ELBO, JitTraceEnum_ELBO, SVI\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.8.4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "PyTorch 1.0 includes a jit compiler to speed up models. You can think of compilation as a “static mode”, whereas PyTorch usually operates in “eager mode”.\n",
    "\n",
    "Pyro supports the jit compiler in two ways. First you can use compiled functions inside Pyro models (but those functions cannot contain Pyro primitives). Second, you can use Pyro’s jit inference algorithms to compile entire inference steps; in static models this can reduce the Python overhead of Pyro models and speed up inference.\n",
    "\n",
    "The rest of this tutorial focuses on Pyro’s jitted inference algorithms: JitTrace_ELBO, JitTraceGraph_ELBO, JitTraceEnum_ELBO, JitMeanField_ELBO, HMC(jit_compile=True), and NUTS(jit_compile=True).\n",
    "\n",
    "## A simple model\n",
    "Let’s start with a simple Gaussian model and an autoguide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    loc = pyro.sample(\"loc\", dist.Normal(0., 10.))\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0., 3.))\n",
    "    with pyro.plate(\"data\", data.size(0)):\n",
    "        pyro.sample(\"obs\", dist.Normal(loc, scale), obs=data)\n",
    "\n",
    "guide = AutoDiagonalNormal(model)\n",
    "\n",
    "data = dist.Normal(0.5, 2.).sample((100,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let’s run as usual with an SVI object and Trace_ELBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 941 ms, sys: 7.34 ms, total: 949 ms\n",
      "Wall time: 949 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "elbo = Trace_ELBO()\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(2 if smoke_test else 1000):\n",
    "    svi.step(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to run with a jit compiled inference, we simply replace\n",
    "```\n",
    "- elbo = Trace_ELBO()\n",
    "+ elbo = JitTrace_ELBO()\n",
    "```\n",
    "Also note that the AutoDiagonalNormal guide behaves a little differently on its first invocation (it runs the model to produce a prototype trace), and we don’t want to record this warmup behavior when compiling. Thus we call the guide(data) once to initialize, then run the compiled SVI,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 501 ms, sys: 6.57 ms, total: 508 ms\n",
      "Wall time: 508 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "\n",
    "guide(data)   # Do any lazy initialization before compiling\n",
    "\n",
    "elbo = JitTrace_ELBO()\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(2 if smoke_test else 1000):\n",
    "    svi.step(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have a more than 2x speedup for this small model.\n",
    "\n",
    "Let us now use the same model, but we will instead use MCMC to generate samples from the model’s posterior. We will use the No-U-Turn(NUTS) sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [00:00, 340.18it/s, step size=1.19e+00, acc. prob=0.891]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 582 ms, sys: 7.72 ms, total: 590 ms\n",
      "Wall time: 590 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nuts_kernel = NUTS(model)\n",
    "pyro.set_rng_seed(1)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=100).run(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compile the potential energy computation in NUTS using the jit_compile=True argument to the NUTS kernel. We also silence JIT warnings due to the presence of tensor constants in the model by using ignore_jit_warnings=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [00:00, 523.08it/s, step size=1.25e+00, acc. prob=0.862]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 6.17 ms, total: 385 ms\n",
      "Wall time: 384 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\n",
    "pyro.set_rng_seed(1)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=100).run(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice some increase in sampling throughput when JIT compilation is enabled."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying structure\n",
    "Time series models often run on datasets of multiple time series with different lengths. To accomodate varying structure like this, Pyro requires models to separate all model inputs into tensors and non-tensors.\n",
    "\n",
    "* Non-tensor inputs should be passed as **kwargs to the model and guide. These can determine model structure, so that a model is compiled for each value of the passed **kwargs.\n",
    "\n",
    "* Tensor inputs should be passed as *args. These must not determine model structure. However len(args) may determine model structure (as is used e.g. in semisupervised models).\n",
    "\n",
    "To illustrate this with a time series model, we will pass in a sequence of observations as a tensor arg and the sequence length as a non-tensor kwarg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sequence, num_sequences, length, state_dim=16):\n",
    "    # This is a Gaussian HMM model.\n",
    "    with pyro.plate(\"states\", state_dim):\n",
    "        trans = pyro.sample(\"trans\", dist.Dirichlet(0.5 * torch.ones(state_dim)))\n",
    "        emit_loc = pyro.sample(\"emit_loc\", dist.Normal(0., 10.))\n",
    "    emit_scale = pyro.sample(\"emit_scale\", dist.LogNormal(0., 3.))\n",
    "\n",
    "    # We're doing manual data subsampling, so we need to scale to actual data size.\n",
    "    with poutine.scale(scale=num_sequences):\n",
    "        # We'll use enumeration inference over the hidden x.\n",
    "        x = 0\n",
    "        for t in pyro.markov(range(length)):\n",
    "            x = pyro.sample(\"x_{}\".format(t), dist.Categorical(trans[x]),\n",
    "                            infer={\"enumerate\": \"parallel\"})\n",
    "            pyro.sample(\"y_{}\".format(t), dist.Normal(emit_loc[x], emit_scale),\n",
    "                        obs=sequence[t])\n",
    "\n",
    "guide = AutoDiagonalNormal(poutine.block(model, expose=[\"trans\", \"emit_scale\", \"emit_loc\"]))\n",
    "\n",
    "# This is fake data of different lengths.\n",
    "lengths = [24] * 50 + [48] * 20 + [72] * 5\n",
    "sequences = [torch.randn(length) for length in lengths]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run SVI as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 2.1 s, total: 18.2 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(1 if smoke_test else 10):\n",
    "    for sequence in sequences:\n",
    "        svi.step(sequence,                                            # tensor args\n",
    "                 num_sequences=len(sequences), length=len(sequence))  # non-tensor args"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we’ll simply swap in a Jit* implementation\n",
    "\n",
    "```\n",
    "- elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "+ elbo = JitTraceEnum_ELBO(max_plate_nesting=1)\n",
    "```\n",
    "\n",
    "Note that we are manually specifying the max_plate_nesting arg. Usually Pyro can figure this out automatically by running the model once on the first invocation; however to avoid this extra work when we run the compiler on the first step, we pass this in manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 2.38 s, total: 21.3 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Do any lazy initialization before compiling.\n",
    "guide(sequences[0], num_sequences=len(sequences), length=len(sequences[0]))\n",
    "\n",
    "elbo = JitTraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(1 if smoke_test else 10):\n",
    "    for sequence in sequences:\n",
    "        svi.step(sequence,                                            # tensor args\n",
    "                 num_sequences=len(sequences), length=len(sequence))  # non-tensor args"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly we don't see any improvement in the computation time! Further investigation may be required!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyroVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
